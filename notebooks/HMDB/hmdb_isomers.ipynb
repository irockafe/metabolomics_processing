{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from lxml import etree\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "\n",
    "# My code\n",
    "import data.preprocessing as preproc\n",
    "import project_fxns.combine_by_mz as combine_mz\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get hmdb data\n",
    "local = '/home/ubuntu/users/isaac/projects/'\n",
    "path = '/revo_healthcare/data/raw/HMDB/'\n",
    "f_name = 'hmdb_serum_metabolite_db_20170813.xml'\n",
    "xml_file = local+path+f_name\n",
    "\n",
    "pickle_path = local + path + 'hmdb_serumdb_20170813_dict.p'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: make all this so that it checks if these files are present - Claire sent an email about a fxn that helps do this in the past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made it through 1000 metabolites\n",
      "Made it through 2000 metabolites\n",
      "Made it through 3000 metabolites\n",
      "Made it through 4000 metabolites\n",
      "Made it through 5000 metabolites\n",
      "Made it through 6000 metabolites\n",
      "Made it through 7000 metabolites\n",
      "Made it through 8000 metabolites\n",
      "Made it through 9000 metabolites\n",
      "Made it through 10000 metabolites\n",
      "Made it through 11000 metabolites\n",
      "Made it through 12000 metabolites\n",
      "Made it through 13000 metabolites\n",
      "Made it through 14000 metabolites\n",
      "Made it through 15000 metabolites\n",
      "Made it through 16000 metabolites\n",
      "Made it through 17000 metabolites\n",
      "Made it through 18000 metabolites\n",
      "Made it through 19000 metabolites\n",
      "Made it through 20000 metabolites\n",
      "Made it through 21000 metabolites\n",
      "Made it through 22000 metabolites\n",
      "Made it through 23000 metabolites\n",
      "Made it through 24000 metabolites\n",
      "Made it through 25000 metabolites\n",
      "Number of metabolites: 25310\n"
     ]
    }
   ],
   "source": [
    "# namespace - at the top of file. fucks with every tag.\n",
    "# very annoying, so name all tags ns + tag\n",
    "ns = '{http://www.hmdb.ca}'\n",
    "nsmap = {None : ns}\n",
    "# If you're within a metabolite tag\n",
    "count = 0\n",
    "seen_mass = 0\n",
    "d = {}\n",
    "for event, element in etree.iterparse(xml_file, tag=ns+'metabolite'):\n",
    "    tree = etree.ElementTree(element)\n",
    "    # Aggregate info into a dictionary of \n",
    "    # {HMDB_ID: iso_mass}\n",
    "    accession = []\n",
    "    # Get accession number and masses for each metabolite\n",
    "    # Could be multiple accessions. Grab all of them, \n",
    "    # sort to make unique identifier\n",
    "    for elem in tree.iter():\n",
    "        if elem.tag == ns+'accession':\n",
    "            accession.append(elem.text)\n",
    "        # If you just saw a 'mono_mass' entry,\n",
    "        # get the mass value and reset, saying you\n",
    "        # havent seen 'mono_mass' in the text of next metabolite\n",
    "        if (elem.tag == ns+'value') & (seen_mass == 1): \n",
    "                mass = float(elem.text)\n",
    "                seen_mass = 0\n",
    "        if elem.text == 'mono_mass':\n",
    "                seen_mass = 1\n",
    "    elem.clear()\n",
    "    \n",
    "    # sort accession numbers and join with '_'    \n",
    "    accession_key = '_'.join(sorted(accession))\n",
    "    # add to dictionary\n",
    "    if mass:\n",
    "        d[accession_key] = mass\n",
    "        \n",
    "    # reset mass - only add feature if mass listed\n",
    "    mass = None\n",
    "    # reset accession numbers\n",
    "    accession = []\n",
    "\n",
    "    element.clear()\n",
    "    count += 1\n",
    "    if count % 1000 == 0:\n",
    "        print('Made it through ' + str(count) + ' metabolites')\n",
    "\n",
    "#pickle.dump(d, open('serumdb_dict.p', 'wb'))\n",
    "print 'Number of metabolites: %s' % len(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write to file\n",
    "pickle.dump(d, open(pickle_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hmdb_dict = pickle.load(open(pickle_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# masses are entries of dict, yes?\n",
    "hmdb_masses = pd.Series(hmdb_dict, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HMDB0000001_HMDB00001_HMDB04935_HMDB06703_HMDB06704    169.085129\n",
       "HMDB00002                                               74.084396\n",
       "HMDB00005_HMDB06544                                    102.031693\n",
       "HMDB00008                                              104.047340\n",
       "HMDB00010_HMDB04990_HMDB04991                          300.172546\n",
       "dtype: float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmdb_masses[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppm_matrix = combine_mz.ppm_matrix(hmdb_masses, hmdb_masses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ppm_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-72feb56a2427>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# write to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnp_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/hmdb_serumdb_20170813_ppm_matrix.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mppm_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ppm_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# write to file\n",
    "np_path = local+path+'/hmdb_serumdb_20170813_ppm_matrix.npy'\n",
    "np.save(np_path, ppm_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reload it\n",
    "ppm_matrix = np.load(np_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert to upper triangular matrix\n",
    "idx_ppm = np.tril_indices(ppm_matrix.shape[0])\n",
    "ppm_matrix[idx_ppm] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ppm_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-20db698e6b66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Ignore runtime warning - means we're ignoring NaN values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mppm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0misomer_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mppm_matrix\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mppm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0misomer_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0misomer_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ppm_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# get indices whose ppm falls below cutoff\n",
    "# Ignore runtime warning - means we're ignoring NaN values\n",
    "ppm = 30\n",
    "isomer_indices = np.argwhere(ppm_matrix < ppm)\n",
    "isomer_indices.shape\n",
    "print isomer_indices[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write isomer indices to file\n",
    "np.save(local+path+'/hmdb_serumdb_20170813_isomer_indices_%s_ppm.npy' % ppm, isomer_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "isomer_indices = np.load(local+path+'/hmdb_serumdb_20170813_isomer_indices_%s_ppm.npy' % ppm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 percent finished: on 0 of 5\n",
      "it took 0.000571966171265 sec\n",
      "0.4 percent finished: on 2 of 5\n",
      "it took 0.000887155532837 sec\n",
      "0.8 percent finished: on 4 of 5\n",
      "it took 0.000928163528442 sec\n",
      "[[0 1]\n",
      " [2 3]\n",
      " [0 4]\n",
      " [4 5]\n",
      " [1 6]]\n",
      "[array([0, 1, 4, 5, 6]), array([2, 3])]\n"
     ]
    }
   ],
   "source": [
    "# This is super fucking slow\n",
    "\n",
    "def group_isomer_indices(indices):\n",
    "    '''\n",
    "    GOAL:\n",
    "        Given a list of isomer pairs, combine all isomers pairs into \n",
    "        a single group - i.e. [[0,1], [1,5], [2,3]] becomes [[0,1,5], [2,3]]\n",
    "    INPUT:\n",
    "        numpy array (nx2) of index pairs from a square difference-matrix\n",
    "        (same mz's used)\n",
    "    OUTPUT: list of numpy arrays containing the indices of mz-matching\n",
    "        features\n",
    "    BUGS:\n",
    "        Known bug means that if features \n",
    "        # A&B < 30 ppm\n",
    "        #  B&C < 30 ppm, \n",
    "        # But A&C = 50 ppm,\n",
    "        # A,B,C will still be grouped together\n",
    "    '''\n",
    "    output = []\n",
    "    t1 = time.time()\n",
    "    for enum, idx in enumerate(indices):\n",
    "        if enum % 2 == 0:\n",
    "            print '%s percent finished: on %s of %s' % (float(enum) / len(indices),\n",
    "                                                  enum, len(indices))\n",
    "            print 'it took {time} sec'.format(time=time.time() - t1)\n",
    "            t1 = time.time()\n",
    "        #print '\\n\\nfinding indices that match ', idx\n",
    "        \n",
    "        # Find any matches to the current index in the list of indices\n",
    "        match_idx = np.argwhere([np.in1d(idx, poop).any() for poop in indices])\n",
    "        #print 'Indices that match\\n', match_idx\n",
    "        #print 'Do these match %s?: \\n %s' % (idx, indices[match_idx])\n",
    "        unique_matches = np.unique(indices[match_idx])\n",
    "        #print 'Unique matches', unique_matches\n",
    "        \n",
    "        # Check if any values from unique_matches are present in output\n",
    "        # if not, append\n",
    "        # if so, append to place where they're found\n",
    "        in_output = [np.in1d(unique_matches, poop).any() for poop in output]\n",
    "        #print 'Output\\n', output\n",
    "        #print 'Is it in the output?\\n', in_output\n",
    "        where_in_output = np.argwhere(in_output)\n",
    "        #print 'Where?\\n', where_in_output, 'Size', where_in_output.size, 'Greater than 1?', where_in_output.size\n",
    "        \n",
    "        \n",
    "        # if found in output, append it to where you found it in the output\n",
    "        if  where_in_output.size != 0:\n",
    "            if where_in_output.size > 1:\n",
    "                raise ValueError(('You should only find an index one place in' +\n",
    "                                  'the output. Something is wrong'))\n",
    "            #print 'Append unique vals to entry that overlaps in output'\n",
    "            #print int(where_in_output)\n",
    "            #print output[int(where_in_output)]\n",
    "            \n",
    "            # append new indices to thos already in output\n",
    "            output[int(where_in_output)] = np.append(output[int(where_in_output)],\n",
    "                                                     unique_matches)\n",
    "        # If not found in an entry of the output, append values found to the output \n",
    "        else:\n",
    "            output.append(unique_matches)\n",
    "        #print 'Output', output\n",
    "        #\n",
    "    # Eliminate repeat values\n",
    "    output = [np.unique(poop) for poop in output]\n",
    "    #print ('-'*50, 'Final output\\n', output)\n",
    "    return output\n",
    "\n",
    "\n",
    "test = np.array([[0,1], [2,3], [0,4], [4,5], [1,6]])\n",
    "\n",
    "iso = group_isomer_indices(test)\n",
    "print test\n",
    "print iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6329396, 2)\n",
      "0.0 percent finished: on 0 of 6329396\n",
      "it took 0.000218868255615 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-49a0945bac03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# A,B,C will still be grouped together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0misomer_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0misomers_groupped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_isomer_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misomer_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-132-6f5367e395d8>\u001b[0m in \u001b[0;36mgroup_isomer_indices\u001b[0;34m(indices)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Find any matches to the current index in the list of indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mmatch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpoop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;31m#print 'Indices that match\\n', match_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m#print 'Do these match %s?: \\n %s' % (idx, indices[match_idx])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/envs/isaac_revo_healthcare/lib/python2.7/site-packages/numpy/lib/arraysetops.pyc\u001b[0m in \u001b[0;36min1d\u001b[0;34m(ar1, ar2, assume_unique, invert)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mar2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m                 \u001b[0mmask\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mar1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# group indices that are found together\n",
    "# TODO: Known bug means that if features \n",
    "# A&B < 30 ppm\n",
    "#  B&C < 30 ppm, \n",
    "# But A&C = 50 ppm,\n",
    "# A,B,C will still be grouped together\n",
    "print isomer_indices.shape\n",
    "isomers_groupped = group_isomer_indices(isomer_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "[[  0 100  15]\n",
      " [100   0  90]\n",
      " [ 15  90   0]]\n",
      "Finished 0.0, working on 0 of 3\n",
      "Took 0.000174999237061 sec\n",
      "[0 2]\n",
      "[1]\n",
      "Finished 0.666666666667, working on 2 of 3\n",
      "Took 0.00140595436096 sec\n",
      "[0 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0, 2]), array([1])]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - fix this - it takes too long\n",
    "# 7 seconds for 25,000 molecules ends up being\n",
    "# 48 hours of run-time\n",
    "\n",
    "def isomers_from_ppm_matrix(ppm_matrix, ppm):\n",
    "    bool_idx = ppm_matrix < ppm\n",
    "    #print '\\nGreater than ppm?:\\n', bool_idx\n",
    "    \n",
    "    # Get indices where isomer\n",
    "    iso_idx = np.argwhere(bool_idx)\n",
    "    #print iso_idx\n",
    "    \n",
    "    collect = []\n",
    "    # Get isomers from every entry\n",
    "    t1 = time.time()\n",
    "    for idx in range(0, ppm_matrix.shape[0]):\n",
    "        if idx % 2 == 0:\n",
    "            print 'Finished {perc}, working on {num} of {total}'.format(\n",
    "                perc= float(idx) / ppm_matrix.shape[0], num=idx,\n",
    "                total=ppm_matrix.shape[0])\n",
    "            print 'Took {time} sec'.format(time=time.time() - t1)\n",
    "            t1 = time.time()\n",
    "        idx_one_feature = [i[0] == idx for i in iso_idx]\n",
    "        isomers_one_feature = np.unique(iso_idx[idx_one_feature,:])\n",
    "        \n",
    "        ### add to output if not already present in collect\n",
    "        \n",
    "        # If single entry\n",
    "        #if type(isomers_one_feature) == bool\n",
    "        print isomers_one_feature\n",
    "        present = any(\n",
    "                        (isomers_one_feature == i).all() for i in collect\n",
    "                      )\n",
    "        #print present\n",
    "        if not present:\n",
    "            collect.append(isomers_one_feature)\n",
    "        #print collect\n",
    "        \n",
    "    return collect\n",
    "\n",
    "toy_ppm = np.array([[0, 100, 15],\n",
    "                    [100, 0, 90 ],\n",
    "                    [15, 90, 0]]\n",
    "                  ) # not additive ppms\n",
    "print 'Input:\\n', toy_ppm\n",
    "isomers_from_ppm_matrix(toy_ppm, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 0.0, working on 0 of 25310\n",
      "Took 0.000861883163452 sec\n",
      "[  0 254]\n",
      "[   1 2841]\n",
      "Finished 7.90201501383e-05, working on 2 of 25310\n",
      "Took 14.3407011032 sec\n",
      "[ 2 39]\n",
      "[  3   5  15 204 211 240 378 388]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/isaac_revo_healthcare/lib/python2.7/site-packages/ipykernel/__main__.py:28: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-6d9f2246bc12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mppm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0misomers_30ppm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misomers_from_ppm_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mppm_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mppm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-130-844d09130f1f>\u001b[0m in \u001b[0;36misomers_from_ppm_matrix\u001b[0;34m(ppm_matrix, ppm)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0misomers_one_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         present = any(\n\u001b[0;32m---> 28\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0misomers_one_feature\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                       )\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#print present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-130-844d09130f1f>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((i,))\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0misomers_one_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         present = any(\n\u001b[0;32m---> 28\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0misomers_one_feature\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                       )\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#print present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'all'"
     ]
    }
   ],
   "source": [
    "# This will take forever. Be less stupid,\n",
    "# you piece of garbage\n",
    "ppm = 30\n",
    "isomers_30ppm = isomers_from_ppm_matrix(ppm_matrix, ppm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(True) == bool"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:isaac_revo_healthcare]",
   "language": "python",
   "name": "conda-env-isaac_revo_healthcare-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
